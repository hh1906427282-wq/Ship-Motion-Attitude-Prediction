import os
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
import seaborn as sns
from model.predictor import Predictor

# ---------- å‚æ•° ----------
input_len = 300
pred_len = 100
input_dim = 18
labels = ['x', 'y', 'z', 'rx', 'ry', 'rz']
groups = ['pos', 'vel', 'acc']  # å¯¹åº”ï¼šä½ç½®ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦

# ---------- åŠ è½½ scaler å’Œæµ‹è¯•æ•°æ® ----------
scaler: MinMaxScaler = joblib.load("scaler_cnn_bilstm_attention.save")
test_data = np.load("test_input_data.npy")  # [T, 18]
total_len = len(test_data)
print(f"âœ… åŠ è½½æµ‹è¯•æ•°æ®ï¼Œå…± {total_len} å¸§ â‰ˆ {total_len * 0.1:.1f} ç§’")

# ---------- åŠ è½½æ¨¡å‹ ----------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Predictor(input_dim=input_dim, pred_len=pred_len).to(device)
model.load_state_dict(torch.load("checkpoints/best_model.pth", map_location=device))
model.eval()
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

# ---------- æ»‘çª—è¿ç»­é¢„æµ‹ ----------
predictions = []
ground_truths = []
attention_saved = False  # åªä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ³¨æ„åŠ›å›¾

start_indices = list(range(0, total_len - input_len - pred_len + 1, pred_len))  # æ¯100å¸§æ»‘çª—

for step_idx, start_idx in enumerate(start_indices):
    x_input = test_data[start_idx:start_idx + input_len]
    y_true = test_data[start_idx + input_len:start_idx + input_len + pred_len]

    x_tensor = torch.tensor(x_input, dtype=torch.float32).unsqueeze(0).to(device)
    with torch.no_grad():
        y_pred_tensor, attn_weights = model(x_tensor)

    y_pred = y_pred_tensor.cpu().numpy().squeeze()  # [100, 18]

    y_true_inv = scaler.inverse_transform(y_true)
    y_pred_pad = np.zeros_like(y_true)
    y_pred_pad[:, :18] = y_pred
    y_pred_inv = scaler.inverse_transform(y_pred_pad)

    ground_truths.append(y_true_inv)
    predictions.append(y_pred_inv)

    # ---------- æ³¨æ„åŠ›å¯è§†åŒ–ï¼šä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬ ----------
    if not attention_saved:
        attn_map = attn_weights.squeeze(0).cpu().numpy()  # [T=300, D=128]
        np.savetxt("fusion_attention_weights.csv", attn_map, delimiter=",")
        print("âœ… èåˆæ³¨æ„åŠ›æƒé‡å·²ä¿å­˜ï¼šfusion_attention_weights.csv")

        # ç»˜å›¾
        plt.figure(figsize=(12, 6))
        sns.heatmap(attn_map.T, cmap='viridis', cbar=True)
        plt.xlabel("Time step (0~299)")
        plt.ylabel("Feature dim (0~127)")
        plt.title("Fusion Attention Heatmap (BiLSTM vs Transformer)")
        plt.tight_layout()
        plt.savefig("fusion_attention_heatmap.png", dpi=300)
        plt.close()
        print("âœ… æ³¨æ„åŠ›çƒ­å›¾å·²ä¿å­˜ï¼šfusion_attention_heatmap.png")

        attention_saved = True

# ---------- æ‹¼æ¥ç»“æœ ----------
y_true_full = np.vstack(ground_truths)
y_pred_full = np.vstack(predictions)
frame_rate = 10  # 10Hz
total_pred_len = y_true_full.shape[0]
time_axis = np.linspace(0, total_pred_len / frame_rate, total_pred_len)

# ---------- ä¿å­˜å›¾åƒ ----------
save_dir = 'figures'
os.makedirs(save_dir, exist_ok=True)

for i, label in enumerate(labels):
    for g in range(3):
        index = i + g * 6
        plt.figure(figsize=(10, 4))
        plt.plot(time_axis, y_true_full[:, index], label='True', color='blue')
        plt.plot(time_axis, y_pred_full[:, index], label='Predicted', color='red', linestyle='--')
        plt.title(f'{label.upper()}-{groups[g]} Prediction')
        plt.xlabel('Time (s)')
        plt.ylabel(f'{label}_{groups[g]}')
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        path = os.path.join(save_dir, f'{label}_{groups[g]}_testset.png')
        plt.savefig(path, dpi=300)
        plt.close()
        print(f"âœ… å›¾åƒå·²ä¿å­˜ï¼š{path}")

# ---------- è¯¯å·®è¯„ä¼° ----------
print("\nğŸ“Š æ•´ä½“é¢„æµ‹è¯¯å·®ï¼ˆ2000sæµ‹è¯•é›†ï¼‰ï¼š")
for g in range(3):
    print(f"\nã€{groups[g].upper()}ã€‘")
    for i, label in enumerate(labels):
        index = i + g * 6
        true = y_true_full[:, index]
        pred = y_pred_full[:, index]
        rmse = math.sqrt(mean_squared_error(true, pred))
        mae = mean_absolute_error(true, pred)
        mape = np.mean(np.abs((true - pred) / (true + 1e-8))) * 100
        r2 = r2_score(true, pred)
        print(f"{label.upper()} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | MAPE: {mape:.2f}% | RÂ²: {r2:.4f}")

# ---------- ä¿å­˜ CSV ----------
results = []
for t in range(total_pred_len):
    row = {'Time (s)': round(time_axis[t], 2)}
    for g in range(3):
        for i, label in enumerate(labels):
            index = i + g * 6
            row[f'{label}_{groups[g]}_True'] = y_true_full[t, index]
            row[f'{label}_{groups[g]}_Pred'] = y_pred_full[t, index]
    results.append(row)

df_result = pd.DataFrame(results)
df_result.to_csv('cnn_bilstm_attention_multitask_prediction_testset.csv', index=False)
print("âœ… å¤šä»»åŠ¡é¢„æµ‹ç»“æœå·²ä¿å­˜ä¸º cnn_bilstm_attention_multitask_prediction_testset.csv")
